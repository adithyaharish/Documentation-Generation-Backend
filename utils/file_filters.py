# 📄 File: utils/file_filters.py
import openai,json
import os
from dotenv import load_dotenv
load_dotenv()

EXCLUDE_PATHS = [
    # General system/tooling
    '.git', '.github', '.vscode', '.idea', 'logs', 'tmp', 'temp',
    'build', 'dist', 'out', 'bin', 'obj', 'coverage', 'docs',

    # Python
    '__pycache__', 'venv', '.venv', '.pytest_cache',

    # JS/TS
    'node_modules', '.next', '.nuxt', '.vercel', '.turbo', '.eslintcache', 'storybook-static', 'cypress','public', 'static',

    # Java/Android
    'target', '.settings', 'app/build', 'app/src/debug', 'test', 'androidTest',

    # Flutter/Dart
    'windows/runner', 'ios/Runner', 'macos/Runner', '.dart_tool', '.packages',

    # C/C++/Rust
    'CMakeFiles', 'cmake-build-debug', 'Makefile', 'target', '.cargo'
]

openai.api_key = os.getenv("OPENAI_API_KEY")

def filter_chunks_with_gpt(chunks, structure_lookup):
    # Step 1: Build GPT input format
    file_list = []
    for chunk in chunks:
        for file in chunk:
            language = structure_lookup.get(file, {}).get("language", "unknown")
            file_list.append({"file": file, "language": language})

    # Step 2: Craft prompt
    prompt = (
        "You are a software expert helping clean a codebase.\n"
        "Below is a list of files and their languages.\n"
        "Remove any that are:\n"
        "- Generated by frameworks or build tools (e.g., gatsby-browser.js)\n"
        "- Not written by developers (e.g., config files, .env, migrations, public folder, node modules)\n"
        "- Not useful for application-level documentation\n\n"
        f"{file_list}\n\n"
        "Return only the list of relevant application-specific files as a JSON array, keep the file and language keys."
    )

    response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",  # This specifies the model you're using
    messages=[
            {"role": "system", "content": "You are an expert software engineer."},
            {"role": "user", "content": prompt}
        ],
    )

    print("GPT CALLED")
    # Step 4: Parse result
    try:
        raw = response.choices[0].message["content"]
        start = raw.find("[")
        end = raw.rfind("]") + 1
        clean = raw[start:end] if start != -1 and end != -1 else raw
        filtered_files = json.loads(clean)
        allowed_files = set(item["file"] for item in filtered_files)
        filtered_chunks = [chunk for chunk in chunks if any(f in allowed_files for f in chunk)]
        formatted_chunks = [{f} for chunk in filtered_chunks for f in chunk if f in allowed_files]
        return formatted_chunks
    except Exception as e:
        print("❌ GPT filtering failed:", e)
        return chunks


def is_excluded_path(path: str) -> bool:
    path = path.replace("\\", "/").lower()
    return any(excl in path for excl in EXCLUDE_PATHS)

def get_chunk_group_map(chunks):
    """
    Return grouped chunk structure as a dict.
    Example: {'src/utils': ['index.js', 'sr.js']}
    Automatically groups by deepest shared folder.
    """
    from collections import defaultdict
    import os

    group_map = defaultdict(list)

    for chunk in chunks:
        for file in chunk:
            path_parts = file.replace("\\", "/").split("/")
            if len(path_parts) > 1:
                folder = "/".join(path_parts[:-1])  # all parts except filename
            else:
                folder = "root"
            filename = path_parts[-1]
            group_map[folder].append(filename)

    return dict(group_map)

def convert_chunks_to_list_of_sets(chunks):
    """
    Converts chunk sets into a list of string sets for JSON serializable output.
    """
    return [set(chunk) for chunk in chunks]